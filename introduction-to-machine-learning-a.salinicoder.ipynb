{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "289d4cd8",
   "metadata": {},
   "source": [
    "# What is Machine Learning?\n",
    "\n",
    "Machine Learning (ML) is a subfield of artificial intelligence (AI) that focuses on building systems that learn from data. By identifying patterns in data, machine learning algorithms can make predictions or decisions without being explicitly programmed to perform the task.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "- **Supervised Learning**: The algorithm is trained on a labeled dataset, where the desired output is already known.\n",
    "  - Examples: Linear Regression, Decision Trees, Support Vector Machines, k-Nearest Neighbors, etc.\n",
    "\n",
    "- **Unsupervised Learning**: The algorithm is trained on an unlabeled dataset, and it must find structure in the data on its own.\n",
    "  - Examples: K-Means Clustering, Hierarchical Clustering, DBSCAN, etc.\n",
    "\n",
    "- **Semi-supervised Learning**: The algorithm is trained on a dataset that contains both labeled and unlabeled data.\n",
    "\n",
    "- **Reinforcement Learning**: The algorithm learns by interacting with an environment and receiving feedback in the form of rewards or penalties.\n",
    "  - Examples: Q-Learning, SARSA, Deep Q Networks (DQN), etc.\n",
    "\n",
    "## Applications\n",
    "\n",
    "Machine learning can be applied to a wide range of problems, including but not limited to:\n",
    "\n",
    "- Image and speech recognition\n",
    "- Natural language processing\n",
    "- Recommendation systems\n",
    "- Autonomous vehicles\n",
    "- Fraud detection\n",
    "- Medical diagnosis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6874a5",
   "metadata": {},
   "source": [
    "# Types of Machine Learning\n",
    "\n",
    "Machine Learning can be broadly categorized into three types:\n",
    "\n",
    "1. **Supervised Learning**\n",
    "    - In supervised learning, the model is trained on a labeled dataset, which means that each training example is paired with an output label. The model makes predictions or decisions based on the input data and is corrected when its predictions are incorrect.\n",
    "    - Examples of supervised learning algorithms include:\n",
    "        - Linear Regression\n",
    "        - Decision Trees\n",
    "        - Support Vector Machines (SVM)\n",
    "        - K-Nearest Neighbors\n",
    "        - Neural Networks\n",
    "    \n",
    "2. **Unsupervised Learning**\n",
    "    - In unsupervised learning, the model is trained on an unlabeled dataset and must find patterns and relationships in the data. There are no output labels to guide the learning process.\n",
    "    - Examples of unsupervised learning algorithms include:\n",
    "        - K-Means Clustering\n",
    "        - Hierarchical Clustering\n",
    "        - DBSCAN\n",
    "        - Principal Component Analysis (PCA)\n",
    "        - Autoencoders\n",
    "        \n",
    "3. **Semi-supervised Learning**\n",
    "    - Semi-supervised learning falls between supervised and unsupervised learning. In semi-supervised learning, the model is trained on a dataset that contains both labeled and unlabeled data. Generally, a small amount of data is labeled while a large amount of data is unlabeled.\n",
    "    - Examples of semi-supervised learning algorithms include:\n",
    "        - Label Propagation\n",
    "        - Self-training\n",
    "        - Co-training\n",
    "        - Multi-view training\n",
    "\n",
    "In addition to these three primary categories, there is also a fourth category known as **Reinforcement Learning**.\n",
    "\n",
    "4. **Reinforcement Learning**\n",
    "    - In reinforcement learning, an agent makes observations and takes actions within an environment, and in return, it receives rewards or penalties. The goal of the agent is to learn to act in a way that will maximize its expected long-term rewards.\n",
    "    - Examples of reinforcement learning algorithms include:\n",
    "        - Q-Learning\n",
    "        - Deep Q Networks (DQN)\n",
    "        - Policy Gradients\n",
    "        - Actor-Critic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70bfa09",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning\n",
    "\n",
    "## Definition\n",
    "Supervised machine learning is a type of machine learning algorithm that is trained on a labeled dataset, where the algorithm is provided with input-output pairs and learns a mapping between inputs and outputs.\n",
    "\n",
    "## Types of Supervised Learning\n",
    "\n",
    "1. **Classification:**\n",
    "    - Classification refers to the task of predicting a discrete class label.\n",
    "    - Examples include email spam filtering, image recognition, and sentiment analysis.\n",
    "    \n",
    "2. **Regression:**\n",
    "    - Regression refers to the task of predicting a continuous value.\n",
    "    - Examples include predicting house prices, stock prices, and temperature.\n",
    "\n",
    "## Components of Supervised Learning\n",
    "\n",
    "1. **Training Data:**\n",
    "    - The dataset used to train the machine learning model, consisting of input-output pairs.\n",
    "    \n",
    "2. **Validation Data:**\n",
    "    - The dataset used to tune hyperparameters and make decisions about which models and model parameters to use.\n",
    "    \n",
    "3. **Test Data:**\n",
    "    - The dataset used to evaluate the performance of the final model.\n",
    "\n",
    "## Steps in Supervised Learning\n",
    "\n",
    "1. **Data Collection:**\n",
    "    - Gather a labeled dataset that will be used to train and evaluate the machine learning model.\n",
    "    \n",
    "2. **Data Preprocessing:**\n",
    "    - Clean and transform the data to make it suitable for training the model.\n",
    "    \n",
    "3. **Feature Engineering:**\n",
    "    - Create new features or modify existing features to improve model performance.\n",
    "    \n",
    "4. **Model Selection:**\n",
    "    - Choose a machine learning model that is suitable for the problem at hand.\n",
    "    \n",
    "5. **Training:**\n",
    "    - Use the training data to train the model, adjusting the model's parameters to minimize the error between the predicted and true outputs.\n",
    "    \n",
    "6. **Evaluation:**\n",
    "    - Use the test data to evaluate the performance of the model and determine how well it generalizes to new, unseen data.\n",
    "    \n",
    "7. **Hyperparameter Tuning:**\n",
    "    - Tune the model's hyperparameters to improve performance.\n",
    "    \n",
    "8. **Deployment:**\n",
    "    - Deploy the model to a production environment where it can make predictions on new data.\n",
    "\n",
    "## Evaluation Metrics\n",
    "\n",
    "- For **Classification** tasks, common evaluation metrics include:\n",
    "    1. Accuracy\n",
    "    2. Precision\n",
    "    3. Recall\n",
    "    4. F1 Score\n",
    "    5. AUC-ROC Curve\n",
    "    \n",
    "- For **Regression** tasks, common evaluation metrics include:\n",
    "    1. Mean Absolute Error (MAE)\n",
    "    2. Mean Squared Error (MSE)\n",
    "    3. Root Mean Squared Error (RMSE)\n",
    "    4. R-squared\n",
    "\n",
    "## Example Algorithms\n",
    "\n",
    "1. **Classification Algorithms:**\n",
    "    - K-Nearest Neighbors (KNN)\n",
    "    - Decision Trees\n",
    "    - Random Forest\n",
    "    - Support Vector Machines (SVM)\n",
    "    - Logistic Regression\n",
    "    - Neural Networks\n",
    "    \n",
    "2. **Regression Algorithms:**\n",
    "    - Linear Regression\n",
    "    - Ridge Regression\n",
    "    - Lasso Regression\n",
    "    - Decision Trees\n",
    "    - Random Forest\n",
    "    - Support Vector Regression (SVR)\n",
    "    - Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf82aa7",
   "metadata": {},
   "source": [
    "# Decision Criteria for Classification vs Regression\n",
    "\n",
    "In machine learning, we often need to make a decision on whether to use classification or regression algorithms for a specific problem. The choice depends on the type of target variable we are trying to predict. Let's break down the criteria:\n",
    "\n",
    "## Classification\n",
    "\n",
    "Classification should be used when:\n",
    "\n",
    "- The target variable is categorical.\n",
    "- You are trying to predict which category or class the data belongs to.\n",
    "- The output is discrete.\n",
    "\n",
    "**Example:**\n",
    "- Predicting whether an email is spam or not spam.\n",
    "- Classifying images of animals as cats, dogs, or birds.\n",
    "\n",
    "## Regression\n",
    "\n",
    "Regression should be used when:\n",
    "\n",
    "- The target variable is continuous.\n",
    "- You are trying to predict a quantity.\n",
    "- The output is a continuous range of values.\n",
    "\n",
    "**Example:**\n",
    "- Predicting house prices based on various features.\n",
    "- Estimating a person's age based on different attributes.\n",
    "\n",
    "## How to Decide\n",
    "\n",
    "1. **Identify the Target Variable:**\n",
    "   - What is the variable you are trying to predict?\n",
    "   \n",
    "2. **Determine the Type of Target Variable:**\n",
    "   - Is the target variable continuous or categorical?\n",
    "   \n",
    "3. **Choose the Appropriate Algorithm:**\n",
    "   - If the target variable is categorical, choose classification.\n",
    "   - If the target variable is continuous, choose regression.\n",
    "\n",
    "This decision framework will help you select the right algorithm for your machine learning problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da63295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN (k-nearest neighbour) - classification\n",
    "#scikit learn python\n",
    "from sklearn import neighbors #scikit learn\n",
    "knn = neighbors.KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb0eb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM (support vector machine)- classification\n",
    "from sklearn import svm  \n",
    "svm = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55b7df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree - classification\n",
    "from sklearn import tree\n",
    "dt = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2208b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression - regression\n",
    "from sklearn import linear_model  \n",
    "lm = linear_model.SGDClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbea66e",
   "metadata": {},
   "source": [
    "# Computing Model Accuracy Using a Classification Algorithm\n",
    "\n",
    "In this notebook, we will discuss how to compute the accuracy of a classification model. The accuracy of a model is a measure of how well the model is able to predict the correct class labels for a given dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8090b8cc",
   "metadata": {},
   "source": [
    "# Selecting the Right Classifier for Your Data\n",
    "\n",
    "When working on a classification problem, choosing the right algorithm is a crucial step. In this note, we will discuss three popular classifiers: k-Nearest Neighbors (knn), Support Vector Machine (svm), and Decision Trees, and how to decide which one to use for your data.\n",
    "\n",
    "## k-Nearest Neighbors (knn)\n",
    "\n",
    "### When to use:\n",
    "- When the dataset is small and simple.\n",
    "- When the data is labeled and contains noise.\n",
    "- When you want a model that is easy to interpret.\n",
    "\n",
    "### Pros and Cons:\n",
    "\n",
    "| Pros                               | Cons                                          |\n",
    "|------------------------------------|-----------------------------------------------|\n",
    "| Simple and easy to understand.     | Sensitive to noisy data and outliers.         |\n",
    "| No need to make assumptions about data distribution. | Computationally expensive.                    |\n",
    "| Can be used for multi-class classification. | Requires feature scaling.                    |\n",
    "\n",
    "\n",
    "## Support Vector Machine (svm)\n",
    "\n",
    "### When to use:\n",
    "- When you have a large dataset.\n",
    "- When the data is labeled and not too noisy.\n",
    "- When the data is not linearly separable (svm with a nonlinear kernel can be used).\n",
    "\n",
    "### Pros and Cons:\n",
    "\n",
    "| Pros                               | Cons                                          |\n",
    "|------------------------------------|-----------------------------------------------|\n",
    "| Effective in high-dimensional spaces. | Sensitive to the choice of the kernel.        |\n",
    "| Can handle non-linear relationships with the kernel trick. | Requires feature scaling.                    |\n",
    "| Works well with clear margin of separation. | May not perform well with noisy data.         |\n",
    "\n",
    "\n",
    "## Decision Tree\n",
    "\n",
    "### When to use:\n",
    "- When you have a dataset with mixed types of variables (e.g., numerical and categorical).\n",
    "- When you want a model that is easy to interpret and visualize.\n",
    "- When the data may not be linearly separable.\n",
    "\n",
    "### Pros and Cons:\n",
    "\n",
    "| Pros                               | Cons                                          |\n",
    "|------------------------------------|-----------------------------------------------|\n",
    "| Can handle both numerical and categorical data. | Can easily overfit, especially with a small dataset. |\n",
    "| Easy to interpret and visualize.   | Sensitive to noisy data.                      |\n",
    "| No need for feature scaling.        | May not perform well with imbalanced datasets.|\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Choosing the right classifier depends on various factors such as the size of the dataset, the type of variables, the presence of noise in the data, and whether the data is linearly separable or not. It's always a good idea to try multiple classifiers and compare their performance using cross-validation before making a decision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24b312f",
   "metadata": {},
   "source": [
    "# Decision Criteria for Classification Algorithms\n",
    "\n",
    "In this notebook, we will discuss the decision criteria for three popular classification algorithms: K-Nearest Neighbors (KNN), Support Vector Machines (SVM), and Decision Trees.\n",
    "\n",
    "## K-Nearest Neighbors (KNN)\n",
    "\n",
    "K-Nearest Neighbors (KNN) is a simple, lazy learning algorithm that classifies a new data point based on the majority voting of its 'k' nearest neighbors.\n",
    "\n",
    "### Decision Criteria:\n",
    "\n",
    "1. **Number of Neighbors (k):**\n",
    "   - The value of 'k' determines the number of neighbors to consider when making the classification decision.\n",
    "   - A small 'k' can lead to a more noisy model, while a large 'k' can lead to a smoother, but potentially less accurate model.\n",
    "\n",
    "2. **Distance Metric:**\n",
    "   - The distance metric determines how the \"nearness\" of data points is calculated.\n",
    "   - Common metrics include Euclidean, Manhattan, and Minkowski distances.\n",
    "\n",
    "3. **Weighting:**\n",
    "   - Weights can be assigned to the neighbors, with closer neighbors having a higher weight than further ones.\n",
    "   - This helps in giving more importance to closer data points during the decision-making process.\n",
    "\n",
    "## Support Vector Machines (SVM)\n",
    "\n",
    "Support Vector Machines (SVM) is a powerful classification algorithm that finds the optimal hyperplane that best separates different classes in the feature space.\n",
    "\n",
    "### Decision Criteria:\n",
    "\n",
    "1. **Kernel:**\n",
    "   - The kernel function transforms the input data into a higher-dimensional space.\n",
    "   - Common kernel functions include linear, polynomial, radial basis function (RBF), and sigmoid.\n",
    "\n",
    "2. **Regularization Parameter (C):**\n",
    "   - The regularization parameter controls the trade-off between achieving a low training error and a low testing error.\n",
    "   - A small 'C' creates a wider margin but more training errors, while a large 'C' creates a narrower margin but fewer training errors.\n",
    "\n",
    "3. **Gamma (in RBF kernel):**\n",
    "   - The gamma parameter defines how far the influence of a single training example reaches.\n",
    "   - Low values mean 'far' and high values mean 'close'.\n",
    "\n",
    "## Decision Trees\n",
    "\n",
    "Decision Trees are a non-linear model used for classification and regression. They recursively split the feature space into homogeneous regions.\n",
    "\n",
    "### Decision Criteria:\n",
    "\n",
    "1. **Splitting Criterion:**\n",
    "   - The splitting criterion determines how the data is split at each node.\n",
    "   - Common splitting criteria include Gini impurity and entropy.\n",
    "\n",
    "2. **Tree Depth:**\n",
    "   - The depth of the tree determines how many splits the tree can make.\n",
    "   - A deeper tree can capture more complex patterns but also has the risk of overfitting.\n",
    "\n",
    "3. **Minimum Samples Split & Minimum Samples Leaf:**\n",
    "   - These parameters control the minimum number of samples required to split an internal node and to be at a leaf node, respectively.\n",
    "   - Adjusting these parameters can help prevent overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1124da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Necessary Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04147d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Display the first 5 rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Preprocess the Data\n",
    "# Handle missing values, encode categorical variables, etc.\n",
    "# ...\n",
    "\n",
    "# Split the Data into Training and Testing Sets\n",
    "X = data.drop('target_column', axis=1)\n",
    "y = data['target_column']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and train the Classification Model\n",
    "clf = YourClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions on the Test Data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute the Accuracy of the Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Display the Accuracy\n",
    "print(f'Model Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17ef338",
   "metadata": {},
   "source": [
    "# Computing Model Accuracy Using a Regression Algorithm\n",
    "\n",
    "Regression algorithms predict a continuous outcome variable (also called dependent variable) based on one or more predictor variables (independent variables). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833959d1",
   "metadata": {},
   "source": [
    "# Decision Criteria for Linear Regression and Logistic Regression Algorithms\n",
    "\n",
    "## Linear Regression\n",
    "\n",
    "Linear regression is a regression algorithm that models the relationship between a dependent variable and one or more independent variables by fitting a linear equation to the observed data.\n",
    "\n",
    "### Decision Criteria for Linear Regression:\n",
    "\n",
    "1. **Coefficient of Determination (R²):**\n",
    "    - R² explains the proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
    "    - R² values range from 0 to 1, where 1 indicates a perfect fit and 0 indicates the model does not explain any variability in the response variable.\n",
    "\n",
    "2. **Mean Squared Error (MSE):**\n",
    "    - MSE is the average of the squares of the errors.\n",
    "    - The smaller the MSE, the better the model.\n",
    "\n",
    "3. **Residuals Plot:**\n",
    "    - Residuals plot helps in checking the assumption of homoscedasticity and linearity.\n",
    "    - The residuals should be randomly scattered around 0.\n",
    "\n",
    "4. **Q-Q Plot (Quantile-Quantile Plot):**\n",
    "    - The Q-Q plot is used to check the normality of the residuals.\n",
    "    - If the residuals are normally distributed, they will fall along a straight line.\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "Logistic regression is a classification algorithm used to model the probability of a certain class or event existing.\n",
    "\n",
    "### Decision Criteria for Logistic Regression:\n",
    "\n",
    "1. **Accuracy:**\n",
    "    - Accuracy is the ratio of the correctly predicted instances to the total instances.\n",
    "    - Higher accuracy means a better model.\n",
    "\n",
    "2. **Confusion Matrix:**\n",
    "    - A confusion matrix is used to understand the performance of the classification algorithm.\n",
    "    - It contains information about the actual and predicted classifications.\n",
    "\n",
    "3. **Precision, Recall, and F1 Score:**\n",
    "    - Precision is the ratio of correctly predicted positive observations to the total predicted positives.\n",
    "    - Recall (Sensitivity) is the ratio of correctly predicted positive observations to all the observations in the actual class.\n",
    "    - F1 Score is the weighted average of Precision and Recall.\n",
    "\n",
    "4. **ROC-AUC Curve:**\n",
    "    - The ROC curve is a graphical representation of the true positive rate against the false positive rate for the different possible cutpoints of a diagnostic test.\n",
    "    - AUC (Area Under the Curve) represents the degree or measure of separability.\n",
    "    - A model with an AUC closer to 1 is a good model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6246af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 2548.07\n",
      "Coefficient of determination: 0.47\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes.target[:-20]\n",
    "diabetes_y_test = diabetes.target[-20:]\n",
    "\n",
    "# Create regression model\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
    "\n",
    "# Compute model accuracy\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f' % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
    "\n",
    "# Coefficient of Determination (R² score)\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(diabetes_y_test, diabetes_y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "# Plot outputs\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
    "plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e23117",
   "metadata": {},
   "source": [
    "## Mean Squared Error (MSE) in Regression Analysis\n",
    "\n",
    "In regression analysis, the Mean Squared Error (MSE) is a metric used to quantify the average of the squares of the errors.\n",
    "\n",
    "The function of MSE in the context of a regression algorithm is to provide a single value that quantifies the average discrepancy between the predicted and actual values. The lower the MSE, the better the model has performed in predicting the outcome variable. MSE offers a means to quantitatively assess the accuracy of the model, and it can be utilized for comparison across different models or algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee5a3bc",
   "metadata": {},
   "source": [
    "# Coefficient of Determination (R² score)\n",
    "\n",
    "The Coefficient of Determination, \\(R²\\) score, is a statistical measure used in the context of statistical models whose main purpose is to predict future outcomes or test hypotheses, based on other related information.\n",
    "\n",
    "In general, a higher \\(R²\\) score indicates a better fit of the model to the data. However, it is important to note that a high \\(R²\\) score does not necessarily imply that the model is the best for predicting future observations, as it may have been overfit to the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45113b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 95.61%\n",
      "Confusion Matrix:\n",
      "[[39  4]\n",
      " [ 1 70]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salinianbalagan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the Data\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Preprocess the Data\n",
    "# Note: The Breast Cancer dataset is already clean, so no additional preprocessing is needed\n",
    "\n",
    "# Split the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Logistic Regression Model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Model Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Additional Evaluation Metrics\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eb68d9",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "The model's performance can be evaluated using various metrics. In this case, we have the model accuracy and the confusion matrix.\n",
    "\n",
    "### Model Accuracy\n",
    "\n",
    "The model accuracy is given as 95.61%, which means the model correctly classified approximately 95.61% of all instances. This is a high accuracy rate, indicating that the model performs well on this particular dataset.\n",
    "\n",
    "### Confusion Matrix\n",
    "\n",
    "The confusion matrix for the model is:\n",
    "In a binary classification problem, the confusion matrix is a 2x2 grid that shows the number of:\n",
    "\n",
    "- True Negatives (TN) - Top-left (39): The instances correctly classified as the negative class.\n",
    "- False Positives (FP) - Top-right (4): The instances incorrectly classified as the positive class.\n",
    "- False Negatives (FN) - Bottom-left (1): The instances incorrectly classified as the negative class.\n",
    "- True Positives (TP) - Bottom-right (70): The instances correctly classified as the positive class.\n",
    "\n",
    "We can use these values to calculate other performance metrics like precision, recall, and F1-score:\n",
    "\n",
    "- Precision (Positive Predictive Value) = $\\frac{TP}{TP + FP}$ = $\\frac{70}{70 + 4} = 0.946$\n",
    "- Recall (Sensitivity) = $\\frac{TP}{TP + FN}$ = $\\frac{70}{70 + 1} = 0.986$\n",
    "- F1-Score = $2 \\times \\frac{(Precision \\times Recall)}{(Precision + Recall)}$ = $2 \\times \\frac{(0.946 \\times 0.986)}{(0.946 + 0.986)} = 0.966$\n",
    "\n",
    "These additional metrics provide a more comprehensive view of the model's performance, considering both false positives and false negatives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baa49fe",
   "metadata": {},
   "source": [
    "### Interpreting the Performance Metrics:\n",
    "\n",
    "1. **Precision (Positive Predictive Value)**:\n",
    "    - Precision is the ratio of True Positives (TP) to the sum of True Positives and False Positives (FP).\n",
    "    - In this case, precision is $0.946$, meaning that $94.6\\%$ of the instances predicted as positive by the model were indeed positive.\n",
    "    - This is a high precision rate, indicating that the model is very accurate when it predicts a positive class.\n",
    "\n",
    "2. **Recall (Sensitivity)**:\n",
    "    - Recall is the ratio of True Positives (TP) to the sum of True Positives and False Negatives (FN).\n",
    "    - In this case, recall is $0.986$, meaning that $98.6\\%$ of all positive instances in the dataset were correctly identified by the model.\n",
    "    - This is an extremely high recall rate, indicating that the model is very good at capturing positive instances.\n",
    "\n",
    "3. **F1-Score**:\n",
    "    - The F1-Score is the harmonic mean of precision and recall. It is a balanced metric that takes into account both false positives and false negatives.\n",
    "    - In this case, the F1-Score is $0.966$, which is a high score, indicating that the model has a good balance between precision and recall.\n",
    "    - The closer the F1-Score is to $1$, the better the model's overall performance.\n",
    "\n",
    "Overall, these metrics indicate that the model performs very well in terms of accurately predicting the positive class, while also capturing most of the positive instances in the dataset. The high F1-Score suggests that the model has a good balance between precision and recall.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
